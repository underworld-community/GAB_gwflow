{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data compilation\n",
    "Uses Aus datasets for the GAB region as an example, but can be modified to extract data for any region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coordinates(x, y, epsg_in, epsg_out):\n",
    "    \"\"\"\n",
    "    Transform between any coordinate system.\n",
    "    **Requires `pyproj`** - install using pip.\n",
    "    Args:\n",
    "        x : float / 1D array\n",
    "            x coordinates (may be in degrees or metres/eastings)\n",
    "        y : float / 1D array\n",
    "            y coordinates (may be in degrees or metres/northings)\n",
    "        epsg_in : int\n",
    "            CRS of x and y coordinates\n",
    "        epsg_out : int\n",
    "            CRS of output\n",
    "    Returns:\n",
    "        x_out : float / list of floats\n",
    "            x coordinates projected in `epsg_out`\n",
    "        y_out : float / list of floats\n",
    "            y coordinates projected in `epsg_out`\n",
    "    \"\"\"\n",
    "    import pyproj\n",
    "\n",
    "    proj_in = pyproj.CRS(\"EPSG:\" + str(epsg_in))\n",
    "    proj_out = pyproj.CRS(\"EPSG:\" + str(epsg_out))\n",
    "    transformer = pyproj.Transformer.from_crs(proj_in, proj_out, always_xy=True)\n",
    "    return transformer.transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use a bounding box in the model coordinate system to extract data in the area of interest\n",
    "xmin, xmax, ymin, ymax = -955637.8812, 1034362.2443650428, 6342298.2975, 8922298.39436168"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to directory where all input data is stored\n",
    "Also where all converted data will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'.../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature data\n",
    "OzTemp available [Here](https://ecat.ga.gov.au/geonetwork/srv/eng/catalog.search#/metadata/70604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load in file that contains the dataset\n",
    "tempData = pd.read_csv(data_dir + \"temperature_data/OzTemp_UncertaintyAssessment_GAB.csv\")\n",
    "\n",
    "# convert to eastings / northings,\n",
    "tempData_eastings, tempData_northings = transform_coordinates(tempData[\"GDA94 Long (DD)\"].to_numpy(),\n",
    "                                                          tempData[\"GDA94 Lat (DD)\"].to_numpy(),\n",
    "                                                          epsg_in=4326, epsg_out=28355)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to data folder, the headers may need to be updated to those contained in the folder\n",
    "\n",
    "df_tempData = pd.DataFrame()\n",
    "df_tempData['Hole No']   = tempData['Hole No']\n",
    "df_tempData['Well Name'] = tempData['Well Name']\n",
    "df_tempData['Longitude'] = tempData[\"GDA94 Long (DD)\"]\n",
    "df_tempData['Latitude']  = tempData[\"GDA94 Lat (DD)\"]\n",
    "df_tempData['Eastings']  = tempData_eastings\n",
    "df_tempData['Northings'] = tempData_northings\n",
    "df_tempData['Depth']     = tempData['Depth of Temp (m)']\n",
    "df_tempData['Temperature'] = tempData['Mu']\n",
    "df_tempData['Temperature stdev'] = tempData['Sigma']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract area of interest\n",
    "df_tempData_bbox = df_tempData[(gw_data['Eastings'] >= xmin) & (df_tempData['Eastings'] <= xmax) & \n",
    "                       (df_tempData['Northings'] >= ymin) & (df_tempData['Northings'] <= ymax)]\n",
    "\n",
    "### save\n",
    "df_tempData_bbox.to_csv(data_dir + \"temperature_OzTemp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recharge data\n",
    "GAB recharge estimates available [Here](https://data.gov.au/data/dataset/fb93be54-4101-4130-9138-215bec4bdad0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = data_dir + 'rch_fnl2_mmyr.xyz'\n",
    "with rasterio.open(file_name) as src:\n",
    "    band1 = src.read(1)\n",
    "    height = band1.shape[0]\n",
    "    width = band1.shape[1]\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rasterio.transform.xy(src.transform, rows, cols)\n",
    "    xcoords = np.array(xs)\n",
    "    ycoords = np.array(ys)\n",
    "    \n",
    "### convert coords\n",
    "recharge_eastings, recharge_northings = transform_coordinates(xcoords, ycoords, epsg_in=4326, epsg_out=28355)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recharge_data = pd.DataFrame()\n",
    "recharge_data['eastings'] = recharge_eastings.flatten()\n",
    "recharge_data['northings'] = recharge_northings.flatten()\n",
    "recharge_data['rechange'] = band1.flatten()\n",
    "\n",
    "### remove NaN values\n",
    "recharge_data = recharge_data[recharge_data['rechange'] > 0]\n",
    "\n",
    "### extract area of interest\n",
    "recharge_data_bbox = recharge_data[(recharge_data['eastings'] >= xmin) & (recharge_data['eastings'] <= xmax) & \n",
    "                                   (recharge_data['northings'] >= ymin) & (recharge_data['northings'] <= ymax)]\n",
    "\n",
    "recharge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groundwater pressure head\n",
    "\n",
    "NGIS groundwater data for Australia can be downloaded from the [BOM groundwater explorer](http://www.bom.gov.au/water/groundwater/explorer/map.shtml)\n",
    "\n",
    "Uses values from pre 2000 to reduce anthropogenic effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import csv\n",
    "import rasterio\n",
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bore_shapefile(shape_filename):\n",
    "    \"\"\"\n",
    "    Read borehole information from NGIS shapefile\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    shape_filename : str\n",
    "        file path of the NGIS shapefile\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boreID : array shape(n,)\n",
    "        unique borehole identifier\n",
    "    lonlat : array shape(n,2)\n",
    "        longitudinal / latitudinal coordinates\n",
    "    coords : array shape(n,2)\n",
    "        eastings / northings in local projected coordinates\n",
    "    proj : array shape(n,)\n",
    "        local projection number\n",
    "    elevation : array shape(n,)\n",
    "        elevation above sea level to well casing\n",
    "    \"\"\"\n",
    "    shp = shpreader.Reader(shape_filename)\n",
    "\n",
    "    n_entries = len(shp)\n",
    "    coords_lonlat = np.empty((n_entries,2))\n",
    "    coords_proj   = np.empty((n_entries,2))\n",
    "    proj          = np.empty(n_entries, dtype=int)\n",
    "    elevation     = np.empty(n_entries)\n",
    "    hydroID       = np.empty(n_entries, dtype=int)\n",
    "    is_hydro      = np.empty(n_entries, dtype=bool)\n",
    "    drilled_depth = np.empty(n_entries)\n",
    "\n",
    "    i = 0\n",
    "    for record in shp.records():\n",
    "        hydroID[i]       = record.attributes['HydroID']\n",
    "        proj[i]          = record.attributes['Projecti_1']\n",
    "        coords_lonlat[i] = record.attributes['Longitude'], record.attributes['Latitude']\n",
    "        coords_proj[i]   = record.attributes['Easting'], record.attributes['Northing']\n",
    "        elevation[i]     = record.attributes['RefElev']\n",
    "        drilled_depth[i] = record.attributes['DrilledDep']\n",
    "        is_hydro[i]      = record.attributes['WaterCount']\n",
    "        i += 1\n",
    "\n",
    "    shp.close()\n",
    "    mask = np.logical_and(is_hydro, drilled_depth > 0)\n",
    "    return hydroID[mask], coords_lonlat[mask], coords_proj[mask], proj[mask], elevation[mask], drilled_depth[mask]\n",
    "\n",
    "def read_water_levels(levels_filename, boreID, min_date=None, max_date=None):\n",
    "    \"\"\"\n",
    "    Read water level information from levels.csv for given boreID\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    levels_filename : str\n",
    "        path to levels.csv file\n",
    "    boreID : array shape(n,)\n",
    "        unique borehole identifier\n",
    "    min_date : datetime\n",
    "        include entries greather than or equal to this datetime\n",
    "    max_date : datetime\n",
    "        include entries less than this datetime\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    levels : array shape(n,)\n",
    "        mean water level in each borehole corresponding to their boreID\n",
    "    levels_std : array shape(n,)\n",
    "        standard deviation of water level in each borehole\n",
    "    \"\"\"\n",
    "    bID, level = np.loadtxt(levels_filename, delimiter=',', usecols=(0,5), skiprows=1, unpack=True)\n",
    "    date = np.loadtxt(levels_filename, delimiter=',', usecols=(3,), skiprows=1, unpack=True, dtype=np.datetime64)\n",
    "    bID = bID.astype(int)\n",
    "\n",
    "    if min_date is None and max_date is None:\n",
    "        pass\n",
    "    else:    \n",
    "        # create a range if min_date or max_date is not NoneType\n",
    "        if min_date is None:\n",
    "            min_date = np.datetime64('0')\n",
    "        if max_date is None:\n",
    "            max_date = np.datetime64('3000')\n",
    "        \n",
    "        # filter data to within date range\n",
    "        mask_date = np.logical_and(date >= min_date, date < max_date)\n",
    "        bID = bID[mask_date]\n",
    "        level = level[mask_date]\n",
    "\n",
    "    mean_std_levels = np.empty((len(boreID), 2))\n",
    "\n",
    "    for i, ID in enumerate(boreID):\n",
    "        mask_ID = bID == ID\n",
    "        if mask_ID.any():\n",
    "            level_ID = level[mask_ID]\n",
    "            mean_std_levels[i] = level_ID.mean(), np.std(level_ID)\n",
    "        else:\n",
    "            mean_std_levels[i] = np.nan\n",
    "            \n",
    "    return tuple(mean_std_levels.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract borehole data from shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states  =  [\"NSW\", \"VIC\", \"ACT\", \"SA\", \"QLD\", \"TAS\", \"NT\", \"WA\"]\n",
    "shapefilename = data_dir + \"NGIS_boreholes/gw_shp_{0}/shp_{0}/NGIS_Bore.shp\"\n",
    "levelfilename = data_dir + \"NGIS_boreholes/gw_shp_{0}/shp_{0}/level_{0}.csv\"\n",
    "\n",
    "\n",
    "gw_data = []\n",
    "for state in states:\n",
    "    sf_state = read_bore_shapefile(shapefilename.format(state))\n",
    "    gw_level = read_water_levels(levelfilename.format(state), sf_state[0], None, np.datetime64('2000'))\n",
    "    \n",
    "    gw_state = np.column_stack([np.c_[sf_state], np.c_[gw_level]])\n",
    "    gw_state = gw_state[~np.isnan(gw_level[0])] # mask out no entries\n",
    "    \n",
    "    gw_data.append(gw_state)\n",
    "\n",
    "# concatenate data\n",
    "gw_data = np.vstack(gw_data)\n",
    "gw_ID         = gw_data[:,0]\n",
    "gw_lonlat     = gw_data[:,1:3]\n",
    "gw_coords     = gw_data[:,3:5]\n",
    "gw_proj       = gw_data[:,5]\n",
    "gw_elevation  = gw_data[:,6]\n",
    "gw_depth      = gw_data[:,7]\n",
    "gw_level      = gw_data[:,8]\n",
    "gw_level_std  = gw_data[:,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert coordinate system of gw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert lon / lat to eastings / northings\n",
    "gw_eastings, gw_northings = transform_coordinates(gw_lonlat[:,0], gw_lonlat[:,1], epsg_in=4326, epsg_out=28355)\n",
    "gw_coords = np.c_[gw_eastings, gw_northings]\n",
    "gw_data[:,3:5] = gw_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract area of interest\n",
    "gw_data_bbox = gw_data[(gw_data[:,3] >= xmin) & (gw_data[:,3] <= xmax) & \n",
    "                       (gw_data[:,4] >= ymin) & (gw_data[:,3] <= ymax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save\n",
    "columns = ['ID','lon','lat','easting','northing','projection','elevation',\n",
    "           'gw_bore_depth', 'gw_level', 'gw_level_std']\n",
    "\n",
    "\n",
    "df_head_bbox = pd.DataFrame(gw_data_bbox, columns=columns)\n",
    "df_head_bbox.to_csv(data_dir + 'NGIS_groundwater_levels_to_2000_bbox.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water table\n",
    "\n",
    "The water table is essentially the longwavelength topography. We want to cut out the short wavelength topography, i.e. mountains, which we can accomplish using a minimum filter `scipy.ndimage.percentile_filter(...)`.\n",
    "\n",
    "Australian topography can be accessed [here](https://ecat.ga.gov.au/geonetwork/srv/eng/catalog.search#/metadata/67703).\n",
    "\n",
    "The result can be compared to the water table derived from the GABWRA project which is available [here](https://data.gov.au/dataset/ds-dga-8d1a9fbc-a411-4ac3-b471-7bb81dcaa45b/details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topography = rioxarray.open_rasterio(data_dir + 'AUSBATH09_AMG55_GDA94_500m_model_extent.tiff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up interpolator\n",
    "smooth_topo_interp = RegularGridInterpolator((np.flipud(topography.sel(band=1).y.data), topography.sel(band=1).x.data), np.flipud(topography.sel(band=1).data), bounds_error=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_file = rasterio.open(data_dir + 'GAB_WaterTable_GABWRA_v01/wt.gtiff.tif')\n",
    "wt_data = np.flipud(wt_file.read(1, masked=True))\n",
    "wt_extent = wt_file.bounds.left, wt_file.bounds.right, wt_file.bounds.bottom, wt_file.bounds.top\n",
    "wt_file.close()\n",
    "\n",
    "# get coordinates\n",
    "wt_xcoords = np.linspace(wt_extent[0], wt_extent[1], wt_data.shape[1], endpoint=False)\n",
    "wt_ycoords = np.linspace(wt_extent[2], wt_extent[3], wt_data.shape[0], endpoint=False)\n",
    "wt_xq, wt_yq = np.meshgrid(wt_xcoords, wt_ycoords)\n",
    "\n",
    "# mask coordinates in GAB\n",
    "wt_x = wt_xq[~wt_data.mask]\n",
    "wt_y = wt_yq[~wt_data.mask]\n",
    "wt_z = np.array(wt_data[~wt_data.mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "percentile_range = [1, 5, 10, 15]\n",
    "size_range = [5, 15, 25, 35]\n",
    "\n",
    "grid_range = np.zeros((len(percentile_range), len(size_range)))\n",
    "\n",
    "for i, percentile in enumerate(percentile_range):\n",
    "    for j, size in enumerate(size_range):\n",
    "        elevation = topo_data.copy()\n",
    "        elevation[elevation < -10] = -10\n",
    "        \n",
    "        smooth_elevation = ndimage.percentile_filter(elevation, percentile, size=size)\n",
    "        smooth_topo_interp.values = smooth_elevation\n",
    "        smooth_elevation_interp = smooth_topo_interp((wt_y, wt_x))\n",
    "        \n",
    "        misfit = np.nansum((smooth_elevation_interp - wt_z)**2)\n",
    "        grid_range[i,j] = misfit\n",
    "        \n",
    "        print(\"p{:2.1f}, s{:2d}, l-2 misfit = {:.02e}\".format(percentile, size, misfit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best solution\n",
    "\n",
    "i, j = np.where(grid_range == grid_range.min())\n",
    "percentile = percentile_range[int(i)]\n",
    "size = size_range[int(j)]\n",
    "print(\"Optimal percentile = {}, size = {}\".format(percentile, size))\n",
    "\n",
    "plt.pcolor(percentile_range, size_range, grid_range, shading='auto', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ndimage(data,invalid=None):\n",
    "    \"\"\"\n",
    "    Replace the value of invalid 'data' cells (indicated by 'invalid')\n",
    "    by the value of the nearest valid data cell\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import distance_transform_edt\n",
    "    masked_array = hasattr(data, \"fill_value\")\n",
    "    if masked_array:\n",
    "        mask_fill_value = data.data == data.fill_value\n",
    "        data = data.data.copy()\n",
    "        data[mask_fill_value] = np.nan\n",
    "    else:\n",
    "        data = data.copy()\n",
    "\n",
    "    if invalid is None:\n",
    "        invalid = np.isnan(data)\n",
    "        if masked_array:\n",
    "            invalid += mask_fill_value\n",
    "    ind = distance_transform_edt(invalid, return_distances=False, return_indices=True)\n",
    "    return data[tuple(ind)]\n",
    "\n",
    "# set up water table interpolators\n",
    "wt_interp = RegularGridInterpolator((wt_ycoords, wt_xcoords), fill_ndimage(wt_data), bounds_error=False)\n",
    "wt_interp_nan = RegularGridInterpolator((wt_ycoords, wt_xcoords), wt_data.mask.astype(int),\n",
    "                                        bounds_error=False, fill_value=1)\n",
    "\n",
    "# interpolate water table to DEM grid\n",
    "topo_xq, topo_yq = np.meshgrid(topo_xc, topo_yc)\n",
    "topo_zq = wt_interp((topo_yq, topo_xq), method='linear')\n",
    "\n",
    "# mask regions that are outside GAB\n",
    "topo_zq_mask = wt_interp_nan((topo_yq, topo_xq), method='nearest')\n",
    "topo_zq[topo_zq_mask==1] = np.nan\n",
    "\n",
    "\n",
    "# place inside topo_data and smoooooth\n",
    "elevation = topo_data.copy()\n",
    "elevation[elevation < -10] = -10\n",
    "elevation[~np.isnan(topo_zq)] = topo_zq[~np.isnan(topo_zq)]\n",
    "smooth_elevation = ndimage.percentile_filter(elevation, percentile, size=size)\n",
    "smooth_elevation = fill_ndimage(smooth_elevation) # no gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_diff = elevation - smooth_elevation\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15,15))\n",
    "\n",
    "im1 = ax1.imshow(smooth_elevation, origin='lower', extent=topo_extent, vmin=-10, vmax=1000)\n",
    "im2 = ax2.imshow(topo_data, origin='lower', extent=topo_extent, vmin=-10, vmax=1000)\n",
    "im3 = ax3.imshow(elevation_diff, origin='lower', extent=topo_extent, cmap='BrBG', vmin=-200, vmax=200)\n",
    "\n",
    "ax1.set_title('Smooth')\n",
    "ax2.set_title('Original')\n",
    "ax3.set_title(\"Diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save water table\n",
    "\n",
    "np.savez_compressed(data_dir + \"water_table_surface.npz\",\n",
    "                    data=elevation_diff,\n",
    "                    x=topo_xc, y=topo_yc, extent=topo_extent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
